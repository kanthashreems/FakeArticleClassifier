evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article0.text
Will force exclusive back-off from OOVs.
Perplexity = 533.89, Entropy = 9.06 bits
Computation based on 28 words.
Number of 5-grams hit = 1  (3.57%)
Number of 4-grams hit = 3  (10.71%)
Number of 3-grams hit = 9  (32.14%)
Number of 2-grams hit = 10  (35.71%)
Number of 1-grams hit = 5  (17.86%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article1.text
Will force exclusive back-off from OOVs.
Perplexity = 98.65, Entropy = 6.62 bits
Computation based on 27 words.
Number of 5-grams hit = 3  (11.11%)
Number of 4-grams hit = 4  (14.81%)
Number of 3-grams hit = 17  (62.96%)
Number of 2-grams hit = 2  (7.41%)
Number of 1-grams hit = 1  (3.70%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article2.text
Will force exclusive back-off from OOVs.
Perplexity = 17.01, Entropy = 4.09 bits
Computation based on 16 words.
Number of 5-grams hit = 9  (56.25%)
Number of 4-grams hit = 2  (12.50%)
Number of 3-grams hit = 3  (18.75%)
Number of 2-grams hit = 1  (6.25%)
Number of 1-grams hit = 1  (6.25%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article3.text
Will force exclusive back-off from OOVs.
Perplexity = 120.94, Entropy = 6.92 bits
Computation based on 22 words.
Number of 5-grams hit = 3  (13.64%)
Number of 4-grams hit = 4  (18.18%)
Number of 3-grams hit = 6  (27.27%)
Number of 2-grams hit = 6  (27.27%)
Number of 1-grams hit = 3  (13.64%)
2 OOVs (8.33%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article4.text
Will force exclusive back-off from OOVs.
Perplexity = 223.27, Entropy = 7.80 bits
Computation based on 19 words.
Number of 5-grams hit = 1  (5.26%)
Number of 4-grams hit = 3  (15.79%)
Number of 3-grams hit = 8  (42.11%)
Number of 2-grams hit = 5  (26.32%)
Number of 1-grams hit = 2  (10.53%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article5.text
Will force exclusive back-off from OOVs.
Perplexity = 226.47, Entropy = 7.82 bits
Computation based on 8 words.
Number of 5-grams hit = 0  (0.00%)
Number of 4-grams hit = 1  (12.50%)
Number of 3-grams hit = 3  (37.50%)
Number of 2-grams hit = 3  (37.50%)
Number of 1-grams hit = 1  (12.50%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article6.text
Will force exclusive back-off from OOVs.
Perplexity = 284.67, Entropy = 8.15 bits
Computation based on 9 words.
Number of 5-grams hit = 0  (0.00%)
Number of 4-grams hit = 2  (22.22%)
Number of 3-grams hit = 2  (22.22%)
Number of 2-grams hit = 3  (33.33%)
Number of 1-grams hit = 2  (22.22%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article7.text
Will force exclusive back-off from OOVs.
Perplexity = 194.89, Entropy = 7.61 bits
Computation based on 26 words.
Number of 5-grams hit = 2  (7.69%)
Number of 4-grams hit = 4  (15.38%)
Number of 3-grams hit = 13  (50.00%)
Number of 2-grams hit = 4  (15.38%)
Number of 1-grams hit = 3  (11.54%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article8.text
Will force exclusive back-off from OOVs.
Perplexity = 267.67, Entropy = 8.06 bits
Computation based on 17 words.
Number of 5-grams hit = 0  (0.00%)
Number of 4-grams hit = 2  (11.76%)
Number of 3-grams hit = 9  (52.94%)
Number of 2-grams hit = 5  (29.41%)
Number of 1-grams hit = 1  (5.88%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article9.text
Will force exclusive back-off from OOVs.
Perplexity = 91.40, Entropy = 6.51 bits
Computation based on 12 words.
Number of 5-grams hit = 3  (25.00%)
Number of 4-grams hit = 5  (41.67%)
Number of 3-grams hit = 2  (16.67%)
Number of 2-grams hit = 1  (8.33%)
Number of 1-grams hit = 1  (8.33%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article10.text
Will force exclusive back-off from OOVs.
Perplexity = 12.95, Entropy = 3.69 bits
Computation based on 8 words.
Number of 5-grams hit = 4  (50.00%)
Number of 4-grams hit = 1  (12.50%)
Number of 3-grams hit = 1  (12.50%)
Number of 2-grams hit = 1  (12.50%)
Number of 1-grams hit = 1  (12.50%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article11.text
Will force exclusive back-off from OOVs.
Perplexity = 78.71, Entropy = 6.30 bits
Computation based on 47 words.
Number of 5-grams hit = 10  (21.28%)
Number of 4-grams hit = 16  (34.04%)
Number of 3-grams hit = 13  (27.66%)
Number of 2-grams hit = 6  (12.77%)
Number of 1-grams hit = 2  (4.26%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article12.text
Will force exclusive back-off from OOVs.
Perplexity = 48.71, Entropy = 5.61 bits
Computation based on 27 words.
Number of 5-grams hit = 7  (25.93%)
Number of 4-grams hit = 4  (14.81%)
Number of 3-grams hit = 8  (29.63%)
Number of 2-grams hit = 6  (22.22%)
Number of 1-grams hit = 2  (7.41%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article13.text
Will force exclusive back-off from OOVs.
Perplexity = 75.88, Entropy = 6.25 bits
Computation based on 30 words.
Number of 5-grams hit = 6  (20.00%)
Number of 4-grams hit = 9  (30.00%)
Number of 3-grams hit = 7  (23.33%)
Number of 2-grams hit = 6  (20.00%)
Number of 1-grams hit = 2  (6.67%)
1 OOVs (3.23%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article14.text
Will force exclusive back-off from OOVs.
Perplexity = 86.16, Entropy = 6.43 bits
Computation based on 23 words.
Number of 5-grams hit = 4  (17.39%)
Number of 4-grams hit = 4  (17.39%)
Number of 3-grams hit = 8  (34.78%)
Number of 2-grams hit = 6  (26.09%)
Number of 1-grams hit = 1  (4.35%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article15.text
Will force exclusive back-off from OOVs.
Perplexity = 57.96, Entropy = 5.86 bits
Computation based on 4 words.
Number of 5-grams hit = 0  (0.00%)
Number of 4-grams hit = 1  (25.00%)
Number of 3-grams hit = 1  (25.00%)
Number of 2-grams hit = 1  (25.00%)
Number of 1-grams hit = 1  (25.00%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article16.text
Will force exclusive back-off from OOVs.
Perplexity = 119.03, Entropy = 6.90 bits
Computation based on 22 words.
Number of 5-grams hit = 4  (18.18%)
Number of 4-grams hit = 3  (13.64%)
Number of 3-grams hit = 5  (22.73%)
Number of 2-grams hit = 8  (36.36%)
Number of 1-grams hit = 2  (9.09%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article17.text
Will force exclusive back-off from OOVs.
Perplexity = 61.31, Entropy = 5.94 bits
Computation based on 12 words.
Number of 5-grams hit = 2  (16.67%)
Number of 4-grams hit = 5  (41.67%)
Number of 3-grams hit = 3  (25.00%)
Number of 2-grams hit = 1  (8.33%)
Number of 1-grams hit = 1  (8.33%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article18.text
Will force exclusive back-off from OOVs.
Perplexity = 125.98, Entropy = 6.98 bits
Computation based on 22 words.
Number of 5-grams hit = 3  (13.64%)
Number of 4-grams hit = 4  (18.18%)
Number of 3-grams hit = 4  (18.18%)
Number of 2-grams hit = 6  (27.27%)
Number of 1-grams hit = 5  (22.73%)
2 OOVs (8.33%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article19.text
Will force exclusive back-off from OOVs.
Perplexity = 168.90, Entropy = 7.40 bits
Computation based on 52 words.
Number of 5-grams hit = 4  (7.69%)
Number of 4-grams hit = 19  (36.54%)
Number of 3-grams hit = 21  (40.38%)
Number of 2-grams hit = 4  (7.69%)
Number of 1-grams hit = 4  (7.69%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article20.text
Will force exclusive back-off from OOVs.
Perplexity = 71.80, Entropy = 6.17 bits
Computation based on 18 words.
Number of 5-grams hit = 4  (22.22%)
Number of 4-grams hit = 3  (16.67%)
Number of 3-grams hit = 4  (22.22%)
Number of 2-grams hit = 5  (27.78%)
Number of 1-grams hit = 2  (11.11%)
1 OOVs (5.26%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article21.text
Will force exclusive back-off from OOVs.
Perplexity = 287.22, Entropy = 8.17 bits
Computation based on 13 words.
Number of 5-grams hit = 0  (0.00%)
Number of 4-grams hit = 3  (23.08%)
Number of 3-grams hit = 5  (38.46%)
Number of 2-grams hit = 4  (30.77%)
Number of 1-grams hit = 1  (7.69%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article22.text
Will force exclusive back-off from OOVs.
Perplexity = 395.50, Entropy = 8.63 bits
Computation based on 29 words.
Number of 5-grams hit = 1  (3.45%)
Number of 4-grams hit = 5  (17.24%)
Number of 3-grams hit = 9  (31.03%)
Number of 2-grams hit = 9  (31.03%)
Number of 1-grams hit = 5  (17.24%)
1 OOVs (3.33%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article23.text
Will force exclusive back-off from OOVs.
Perplexity = 167.29, Entropy = 7.39 bits
Computation based on 11 words.
Number of 5-grams hit = 0  (0.00%)
Number of 4-grams hit = 2  (18.18%)
Number of 3-grams hit = 4  (36.36%)
Number of 2-grams hit = 3  (27.27%)
Number of 1-grams hit = 2  (18.18%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article24.text
Will force exclusive back-off from OOVs.
Perplexity = 111.37, Entropy = 6.80 bits
Computation based on 23 words.
Number of 5-grams hit = 1  (4.35%)
Number of 4-grams hit = 5  (21.74%)
Number of 3-grams hit = 11  (47.83%)
Number of 2-grams hit = 4  (17.39%)
Number of 1-grams hit = 2  (8.70%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article25.text
Will force exclusive back-off from OOVs.
Perplexity = 161.95, Entropy = 7.34 bits
Computation based on 35 words.
Number of 5-grams hit = 1  (2.86%)
Number of 4-grams hit = 10  (28.57%)
Number of 3-grams hit = 17  (48.57%)
Number of 2-grams hit = 6  (17.14%)
Number of 1-grams hit = 1  (2.86%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article26.text
Will force exclusive back-off from OOVs.
Perplexity = 32.66, Entropy = 5.03 bits
Computation based on 25 words.
Number of 5-grams hit = 11  (44.00%)
Number of 4-grams hit = 5  (20.00%)
Number of 3-grams hit = 5  (20.00%)
Number of 2-grams hit = 3  (12.00%)
Number of 1-grams hit = 1  (4.00%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article27.text
Will force exclusive back-off from OOVs.
Perplexity = 88.33, Entropy = 6.46 bits
Computation based on 10 words.
Number of 5-grams hit = 1  (10.00%)
Number of 4-grams hit = 2  (20.00%)
Number of 3-grams hit = 4  (40.00%)
Number of 2-grams hit = 2  (20.00%)
Number of 1-grams hit = 1  (10.00%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article28.text
Will force exclusive back-off from OOVs.
Perplexity = 72.70, Entropy = 6.18 bits
Computation based on 27 words.
Number of 5-grams hit = 4  (14.81%)
Number of 4-grams hit = 7  (25.93%)
Number of 3-grams hit = 8  (29.63%)
Number of 2-grams hit = 5  (18.52%)
Number of 1-grams hit = 3  (11.11%)
3 OOVs (10.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article29.text
Will force exclusive back-off from OOVs.
Perplexity = 127.03, Entropy = 6.99 bits
Computation based on 26 words.
Number of 5-grams hit = 2  (7.69%)
Number of 4-grams hit = 10  (38.46%)
Number of 3-grams hit = 9  (34.62%)
Number of 2-grams hit = 4  (15.38%)
Number of 1-grams hit = 1  (3.85%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article30.text
Will force exclusive back-off from OOVs.
Perplexity = 27.95, Entropy = 4.80 bits
Computation based on 12 words.
Number of 5-grams hit = 4  (33.33%)
Number of 4-grams hit = 4  (33.33%)
Number of 3-grams hit = 2  (16.67%)
Number of 2-grams hit = 1  (8.33%)
Number of 1-grams hit = 1  (8.33%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article31.text
Will force exclusive back-off from OOVs.
Perplexity = 332.61, Entropy = 8.38 bits
Computation based on 16 words.
Number of 5-grams hit = 0  (0.00%)
Number of 4-grams hit = 1  (6.25%)
Number of 3-grams hit = 6  (37.50%)
Number of 2-grams hit = 7  (43.75%)
Number of 1-grams hit = 2  (12.50%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article32.text
Will force exclusive back-off from OOVs.
Perplexity = 81.19, Entropy = 6.34 bits
Computation based on 20 words.
Number of 5-grams hit = 2  (10.00%)
Number of 4-grams hit = 5  (25.00%)
Number of 3-grams hit = 8  (40.00%)
Number of 2-grams hit = 3  (15.00%)
Number of 1-grams hit = 2  (10.00%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article33.text
Will force exclusive back-off from OOVs.
Perplexity = 76.56, Entropy = 6.26 bits
Computation based on 18 words.
Number of 5-grams hit = 1  (5.56%)
Number of 4-grams hit = 8  (44.44%)
Number of 3-grams hit = 6  (33.33%)
Number of 2-grams hit = 2  (11.11%)
Number of 1-grams hit = 1  (5.56%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article34.text
Will force exclusive back-off from OOVs.
Perplexity = 118.24, Entropy = 6.89 bits
Computation based on 31 words.
Number of 5-grams hit = 5  (16.13%)
Number of 4-grams hit = 6  (19.35%)
Number of 3-grams hit = 10  (32.26%)
Number of 2-grams hit = 6  (19.35%)
Number of 1-grams hit = 4  (12.90%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article35.text
Will force exclusive back-off from OOVs.
Perplexity = 244.77, Entropy = 7.94 bits
Computation based on 77 words.
Number of 5-grams hit = 7  (9.09%)
Number of 4-grams hit = 15  (19.48%)
Number of 3-grams hit = 29  (37.66%)
Number of 2-grams hit = 19  (24.68%)
Number of 1-grams hit = 7  (9.09%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article36.text
Will force exclusive back-off from OOVs.
Perplexity = 79.93, Entropy = 6.32 bits
Computation based on 25 words.
Number of 5-grams hit = 3  (12.00%)
Number of 4-grams hit = 6  (24.00%)
Number of 3-grams hit = 8  (32.00%)
Number of 2-grams hit = 5  (20.00%)
Number of 1-grams hit = 3  (12.00%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article37.text
Will force exclusive back-off from OOVs.
Perplexity = 69.17, Entropy = 6.11 bits
Computation based on 14 words.
Number of 5-grams hit = 1  (7.14%)
Number of 4-grams hit = 3  (21.43%)
Number of 3-grams hit = 5  (35.71%)
Number of 2-grams hit = 4  (28.57%)
Number of 1-grams hit = 1  (7.14%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article38.text
Will force exclusive back-off from OOVs.
Perplexity = 9.44, Entropy = 3.24 bits
Computation based on 22 words.
Number of 5-grams hit = 14  (63.64%)
Number of 4-grams hit = 3  (13.64%)
Number of 3-grams hit = 3  (13.64%)
Number of 2-grams hit = 1  (4.55%)
Number of 1-grams hit = 1  (4.55%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article39.text
Will force exclusive back-off from OOVs.
Perplexity = 108.96, Entropy = 6.77 bits
Computation based on 22 words.
Number of 5-grams hit = 1  (4.55%)
Number of 4-grams hit = 7  (31.82%)
Number of 3-grams hit = 9  (40.91%)
Number of 2-grams hit = 4  (18.18%)
Number of 1-grams hit = 1  (4.55%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article40.text
Will force exclusive back-off from OOVs.
Perplexity = 41.30, Entropy = 5.37 bits
Computation based on 32 words.
Number of 5-grams hit = 11  (34.38%)
Number of 4-grams hit = 11  (34.38%)
Number of 3-grams hit = 7  (21.88%)
Number of 2-grams hit = 2  (6.25%)
Number of 1-grams hit = 1  (3.12%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article41.text
Will force exclusive back-off from OOVs.
Perplexity = 60.61, Entropy = 5.92 bits
Computation based on 19 words.
Number of 5-grams hit = 6  (31.58%)
Number of 4-grams hit = 3  (15.79%)
Number of 3-grams hit = 5  (26.32%)
Number of 2-grams hit = 4  (21.05%)
Number of 1-grams hit = 1  (5.26%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article42.text
Will force exclusive back-off from OOVs.
Perplexity = 54.74, Entropy = 5.77 bits
Computation based on 48 words.
Number of 5-grams hit = 13  (27.08%)
Number of 4-grams hit = 11  (22.92%)
Number of 3-grams hit = 16  (33.33%)
Number of 2-grams hit = 6  (12.50%)
Number of 1-grams hit = 2  (4.17%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article43.text
Will force exclusive back-off from OOVs.
Perplexity = 291.47, Entropy = 8.19 bits
Computation based on 39 words.
Number of 5-grams hit = 4  (10.26%)
Number of 4-grams hit = 8  (20.51%)
Number of 3-grams hit = 11  (28.21%)
Number of 2-grams hit = 11  (28.21%)
Number of 1-grams hit = 5  (12.82%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article44.text
Will force exclusive back-off from OOVs.
Perplexity = 58.98, Entropy = 5.88 bits
Computation based on 59 words.
Number of 5-grams hit = 20  (33.90%)
Number of 4-grams hit = 12  (20.34%)
Number of 3-grams hit = 12  (20.34%)
Number of 2-grams hit = 13  (22.03%)
Number of 1-grams hit = 2  (3.39%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article45.text
Will force exclusive back-off from OOVs.
Perplexity = 316.96, Entropy = 8.31 bits
Computation based on 23 words.
Number of 5-grams hit = 2  (8.70%)
Number of 4-grams hit = 5  (21.74%)
Number of 3-grams hit = 7  (30.43%)
Number of 2-grams hit = 6  (26.09%)
Number of 1-grams hit = 3  (13.04%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article46.text
Will force exclusive back-off from OOVs.
Perplexity = 208.86, Entropy = 7.71 bits
Computation based on 63 words.
Number of 5-grams hit = 6  (9.52%)
Number of 4-grams hit = 11  (17.46%)
Number of 3-grams hit = 23  (36.51%)
Number of 2-grams hit = 17  (26.98%)
Number of 1-grams hit = 6  (9.52%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article47.text
Will force exclusive back-off from OOVs.
Perplexity = 153.21, Entropy = 7.26 bits
Computation based on 59 words.
Number of 5-grams hit = 10  (16.95%)
Number of 4-grams hit = 10  (16.95%)
Number of 3-grams hit = 21  (35.59%)
Number of 2-grams hit = 15  (25.42%)
Number of 1-grams hit = 3  (5.08%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article48.text
Will force exclusive back-off from OOVs.
Perplexity = 215.44, Entropy = 7.75 bits
Computation based on 35 words.
Number of 5-grams hit = 5  (14.29%)
Number of 4-grams hit = 5  (14.29%)
Number of 3-grams hit = 12  (34.29%)
Number of 2-grams hit = 9  (25.71%)
Number of 1-grams hit = 4  (11.43%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article49.text
Will force exclusive back-off from OOVs.
Perplexity = 219.13, Entropy = 7.78 bits
Computation based on 76 words.
Number of 5-grams hit = 6  (7.89%)
Number of 4-grams hit = 16  (21.05%)
Number of 3-grams hit = 31  (40.79%)
Number of 2-grams hit = 19  (25.00%)
Number of 1-grams hit = 4  (5.26%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article50.text
Will force exclusive back-off from OOVs.
Perplexity = 65.04, Entropy = 6.02 bits
Computation based on 32 words.
Number of 5-grams hit = 2  (6.25%)
Number of 4-grams hit = 11  (34.38%)
Number of 3-grams hit = 13  (40.62%)
Number of 2-grams hit = 5  (15.62%)
Number of 1-grams hit = 1  (3.12%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article51.text
Will force exclusive back-off from OOVs.
Perplexity = 144.72, Entropy = 7.18 bits
Computation based on 22 words.
Number of 5-grams hit = 4  (18.18%)
Number of 4-grams hit = 6  (27.27%)
Number of 3-grams hit = 3  (13.64%)
Number of 2-grams hit = 6  (27.27%)
Number of 1-grams hit = 3  (13.64%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article52.text
Will force exclusive back-off from OOVs.
Perplexity = 60.43, Entropy = 5.92 bits
Computation based on 52 words.
Number of 5-grams hit = 15  (28.85%)
Number of 4-grams hit = 14  (26.92%)
Number of 3-grams hit = 8  (15.38%)
Number of 2-grams hit = 13  (25.00%)
Number of 1-grams hit = 2  (3.85%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article53.text
Will force exclusive back-off from OOVs.
Perplexity = 157.41, Entropy = 7.30 bits
Computation based on 48 words.
Number of 5-grams hit = 12  (25.00%)
Number of 4-grams hit = 8  (16.67%)
Number of 3-grams hit = 16  (33.33%)
Number of 2-grams hit = 6  (12.50%)
Number of 1-grams hit = 6  (12.50%)
2 OOVs (4.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article54.text
Will force exclusive back-off from OOVs.
Perplexity = 71.82, Entropy = 6.17 bits
Computation based on 43 words.
Number of 5-grams hit = 12  (27.91%)
Number of 4-grams hit = 10  (23.26%)
Number of 3-grams hit = 8  (18.60%)
Number of 2-grams hit = 10  (23.26%)
Number of 1-grams hit = 3  (6.98%)
1 OOVs (2.27%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article55.text
Will force exclusive back-off from OOVs.
Perplexity = 203.43, Entropy = 7.67 bits
Computation based on 40 words.
Number of 5-grams hit = 5  (12.50%)
Number of 4-grams hit = 10  (25.00%)
Number of 3-grams hit = 11  (27.50%)
Number of 2-grams hit = 9  (22.50%)
Number of 1-grams hit = 5  (12.50%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article56.text
Will force exclusive back-off from OOVs.
Perplexity = 84.20, Entropy = 6.40 bits
Computation based on 44 words.
Number of 5-grams hit = 8  (18.18%)
Number of 4-grams hit = 16  (36.36%)
Number of 3-grams hit = 13  (29.55%)
Number of 2-grams hit = 4  (9.09%)
Number of 1-grams hit = 3  (6.82%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article57.text
Will force exclusive back-off from OOVs.
Perplexity = 112.15, Entropy = 6.81 bits
Computation based on 16 words.
Number of 5-grams hit = 3  (18.75%)
Number of 4-grams hit = 3  (18.75%)
Number of 3-grams hit = 5  (31.25%)
Number of 2-grams hit = 3  (18.75%)
Number of 1-grams hit = 2  (12.50%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article58.text
Will force exclusive back-off from OOVs.
Perplexity = 594.48, Entropy = 9.22 bits
Computation based on 39 words.
Number of 5-grams hit = 4  (10.26%)
Number of 4-grams hit = 4  (10.26%)
Number of 3-grams hit = 10  (25.64%)
Number of 2-grams hit = 14  (35.90%)
Number of 1-grams hit = 7  (17.95%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article59.text
Will force exclusive back-off from OOVs.
Perplexity = 134.66, Entropy = 7.07 bits
Computation based on 45 words.
Number of 5-grams hit = 7  (15.56%)
Number of 4-grams hit = 15  (33.33%)
Number of 3-grams hit = 12  (26.67%)
Number of 2-grams hit = 6  (13.33%)
Number of 1-grams hit = 5  (11.11%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article60.text
Will force exclusive back-off from OOVs.
Perplexity = 55.56, Entropy = 5.80 bits
Computation based on 45 words.
Number of 5-grams hit = 20  (44.44%)
Number of 4-grams hit = 6  (13.33%)
Number of 3-grams hit = 9  (20.00%)
Number of 2-grams hit = 7  (15.56%)
Number of 1-grams hit = 3  (6.67%)
1 OOVs (2.17%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article61.text
Will force exclusive back-off from OOVs.
Perplexity = 126.23, Entropy = 6.98 bits
Computation based on 40 words.
Number of 5-grams hit = 6  (15.00%)
Number of 4-grams hit = 12  (30.00%)
Number of 3-grams hit = 15  (37.50%)
Number of 2-grams hit = 6  (15.00%)
Number of 1-grams hit = 1  (2.50%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article62.text
Will force exclusive back-off from OOVs.
Perplexity = 175.92, Entropy = 7.46 bits
Computation based on 57 words.
Number of 5-grams hit = 10  (17.54%)
Number of 4-grams hit = 8  (14.04%)
Number of 3-grams hit = 18  (31.58%)
Number of 2-grams hit = 14  (24.56%)
Number of 1-grams hit = 7  (12.28%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article63.text
Will force exclusive back-off from OOVs.
Perplexity = 112.45, Entropy = 6.81 bits
Computation based on 36 words.
Number of 5-grams hit = 10  (27.78%)
Number of 4-grams hit = 8  (22.22%)
Number of 3-grams hit = 6  (16.67%)
Number of 2-grams hit = 9  (25.00%)
Number of 1-grams hit = 3  (8.33%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article64.text
Will force exclusive back-off from OOVs.
Perplexity = 2.58, Entropy = 1.37 bits
Computation based on 18 words.
Number of 5-grams hit = 14  (77.78%)
Number of 4-grams hit = 1  (5.56%)
Number of 3-grams hit = 1  (5.56%)
Number of 2-grams hit = 1  (5.56%)
Number of 1-grams hit = 1  (5.56%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article65.text
Will force exclusive back-off from OOVs.
Perplexity = 61.17, Entropy = 5.93 bits
Computation based on 19 words.
Number of 5-grams hit = 6  (31.58%)
Number of 4-grams hit = 4  (21.05%)
Number of 3-grams hit = 5  (26.32%)
Number of 2-grams hit = 3  (15.79%)
Number of 1-grams hit = 1  (5.26%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article66.text
Will force exclusive back-off from OOVs.
Perplexity = 162.14, Entropy = 7.34 bits
Computation based on 65 words.
Number of 5-grams hit = 9  (13.85%)
Number of 4-grams hit = 12  (18.46%)
Number of 3-grams hit = 25  (38.46%)
Number of 2-grams hit = 17  (26.15%)
Number of 1-grams hit = 2  (3.08%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article67.text
Will force exclusive back-off from OOVs.
Perplexity = 168.66, Entropy = 7.40 bits
Computation based on 54 words.
Number of 5-grams hit = 10  (18.52%)
Number of 4-grams hit = 13  (24.07%)
Number of 3-grams hit = 12  (22.22%)
Number of 2-grams hit = 15  (27.78%)
Number of 1-grams hit = 4  (7.41%)
1 OOVs (1.82%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article68.text
Will force exclusive back-off from OOVs.
Perplexity = 210.70, Entropy = 7.72 bits
Computation based on 64 words.
Number of 5-grams hit = 13  (20.31%)
Number of 4-grams hit = 6  (9.38%)
Number of 3-grams hit = 14  (21.88%)
Number of 2-grams hit = 22  (34.38%)
Number of 1-grams hit = 9  (14.06%)
5 OOVs (7.25%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article69.text
Will force exclusive back-off from OOVs.
Perplexity = 110.25, Entropy = 6.78 bits
Computation based on 48 words.
Number of 5-grams hit = 10  (20.83%)
Number of 4-grams hit = 10  (20.83%)
Number of 3-grams hit = 17  (35.42%)
Number of 2-grams hit = 10  (20.83%)
Number of 1-grams hit = 1  (2.08%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article70.text
Will force exclusive back-off from OOVs.
Perplexity = 118.92, Entropy = 6.89 bits
Computation based on 48 words.
Number of 5-grams hit = 7  (14.58%)
Number of 4-grams hit = 11  (22.92%)
Number of 3-grams hit = 17  (35.42%)
Number of 2-grams hit = 11  (22.92%)
Number of 1-grams hit = 2  (4.17%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article71.text
Will force exclusive back-off from OOVs.
Perplexity = 139.57, Entropy = 7.12 bits
Computation based on 26 words.
Number of 5-grams hit = 4  (15.38%)
Number of 4-grams hit = 8  (30.77%)
Number of 3-grams hit = 7  (26.92%)
Number of 2-grams hit = 5  (19.23%)
Number of 1-grams hit = 2  (7.69%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article72.text
Will force exclusive back-off from OOVs.
Perplexity = 15.95, Entropy = 4.00 bits
Computation based on 46 words.
Number of 5-grams hit = 28  (60.87%)
Number of 4-grams hit = 5  (10.87%)
Number of 3-grams hit = 4  (8.70%)
Number of 2-grams hit = 8  (17.39%)
Number of 1-grams hit = 1  (2.17%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article73.text
Will force exclusive back-off from OOVs.
Perplexity = 60.11, Entropy = 5.91 bits
Computation based on 57 words.
Number of 5-grams hit = 15  (26.32%)
Number of 4-grams hit = 15  (26.32%)
Number of 3-grams hit = 19  (33.33%)
Number of 2-grams hit = 7  (12.28%)
Number of 1-grams hit = 1  (1.75%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article74.text
Will force exclusive back-off from OOVs.
Perplexity = 115.91, Entropy = 6.86 bits
Computation based on 55 words.
Number of 5-grams hit = 10  (18.18%)
Number of 4-grams hit = 7  (12.73%)
Number of 3-grams hit = 17  (30.91%)
Number of 2-grams hit = 17  (30.91%)
Number of 1-grams hit = 4  (7.27%)
1 OOVs (1.79%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article75.text
Will force exclusive back-off from OOVs.
Perplexity = 31.82, Entropy = 4.99 bits
Computation based on 30 words.
Number of 5-grams hit = 10  (33.33%)
Number of 4-grams hit = 11  (36.67%)
Number of 3-grams hit = 6  (20.00%)
Number of 2-grams hit = 2  (6.67%)
Number of 1-grams hit = 1  (3.33%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article76.text
Will force exclusive back-off from OOVs.
Perplexity = 31.46, Entropy = 4.98 bits
Computation based on 45 words.
Number of 5-grams hit = 19  (42.22%)
Number of 4-grams hit = 13  (28.89%)
Number of 3-grams hit = 8  (17.78%)
Number of 2-grams hit = 4  (8.89%)
Number of 1-grams hit = 1  (2.22%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article77.text
Will force exclusive back-off from OOVs.
Perplexity = 151.53, Entropy = 7.24 bits
Computation based on 71 words.
Number of 5-grams hit = 7  (9.86%)
Number of 4-grams hit = 19  (26.76%)
Number of 3-grams hit = 29  (40.85%)
Number of 2-grams hit = 13  (18.31%)
Number of 1-grams hit = 3  (4.23%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article78.text
Will force exclusive back-off from OOVs.
Perplexity = 42.31, Entropy = 5.40 bits
Computation based on 54 words.
Number of 5-grams hit = 24  (44.44%)
Number of 4-grams hit = 12  (22.22%)
Number of 3-grams hit = 13  (24.07%)
Number of 2-grams hit = 4  (7.41%)
Number of 1-grams hit = 1  (1.85%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article79.text
Will force exclusive back-off from OOVs.
Perplexity = 123.85, Entropy = 6.95 bits
Computation based on 54 words.
Number of 5-grams hit = 9  (16.67%)
Number of 4-grams hit = 17  (31.48%)
Number of 3-grams hit = 18  (33.33%)
Number of 2-grams hit = 7  (12.96%)
Number of 1-grams hit = 3  (5.56%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article80.text
Will force exclusive back-off from OOVs.
Perplexity = 142.33, Entropy = 7.15 bits
Computation based on 50 words.
Number of 5-grams hit = 8  (16.00%)
Number of 4-grams hit = 8  (16.00%)
Number of 3-grams hit = 12  (24.00%)
Number of 2-grams hit = 16  (32.00%)
Number of 1-grams hit = 6  (12.00%)
3 OOVs (5.66%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article81.text
Will force exclusive back-off from OOVs.
Perplexity = 333.03, Entropy = 8.38 bits
Computation based on 58 words.
Number of 5-grams hit = 5  (8.62%)
Number of 4-grams hit = 11  (18.97%)
Number of 3-grams hit = 19  (32.76%)
Number of 2-grams hit = 15  (25.86%)
Number of 1-grams hit = 8  (13.79%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article82.text
Will force exclusive back-off from OOVs.
Perplexity = 51.61, Entropy = 5.69 bits
Computation based on 111 words.
Number of 5-grams hit = 41  (36.94%)
Number of 4-grams hit = 23  (20.72%)
Number of 3-grams hit = 26  (23.42%)
Number of 2-grams hit = 18  (16.22%)
Number of 1-grams hit = 3  (2.70%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article83.text
Will force exclusive back-off from OOVs.
Perplexity = 100.11, Entropy = 6.65 bits
Computation based on 57 words.
Number of 5-grams hit = 7  (12.28%)
Number of 4-grams hit = 16  (28.07%)
Number of 3-grams hit = 19  (33.33%)
Number of 2-grams hit = 12  (21.05%)
Number of 1-grams hit = 3  (5.26%)
1 OOVs (1.72%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article84.text
Will force exclusive back-off from OOVs.
Perplexity = 175.52, Entropy = 7.46 bits
Computation based on 76 words.
Number of 5-grams hit = 9  (11.84%)
Number of 4-grams hit = 14  (18.42%)
Number of 3-grams hit = 24  (31.58%)
Number of 2-grams hit = 21  (27.63%)
Number of 1-grams hit = 8  (10.53%)
3 OOVs (3.80%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article85.text
Will force exclusive back-off from OOVs.
Perplexity = 79.84, Entropy = 6.32 bits
Computation based on 36 words.
Number of 5-grams hit = 9  (25.00%)
Number of 4-grams hit = 11  (30.56%)
Number of 3-grams hit = 8  (22.22%)
Number of 2-grams hit = 4  (11.11%)
Number of 1-grams hit = 4  (11.11%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article86.text
Will force exclusive back-off from OOVs.
Perplexity = 64.63, Entropy = 6.01 bits
Computation based on 74 words.
Number of 5-grams hit = 21  (28.38%)
Number of 4-grams hit = 14  (18.92%)
Number of 3-grams hit = 20  (27.03%)
Number of 2-grams hit = 14  (18.92%)
Number of 1-grams hit = 5  (6.76%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article87.text
Will force exclusive back-off from OOVs.
Perplexity = 96.01, Entropy = 6.59 bits
Computation based on 43 words.
Number of 5-grams hit = 13  (30.23%)
Number of 4-grams hit = 8  (18.60%)
Number of 3-grams hit = 12  (27.91%)
Number of 2-grams hit = 6  (13.95%)
Number of 1-grams hit = 4  (9.30%)
1 OOVs (2.27%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article88.text
Will force exclusive back-off from OOVs.
Perplexity = 98.85, Entropy = 6.63 bits
Computation based on 100 words.
Number of 5-grams hit = 18  (18.00%)
Number of 4-grams hit = 28  (28.00%)
Number of 3-grams hit = 32  (32.00%)
Number of 2-grams hit = 19  (19.00%)
Number of 1-grams hit = 3  (3.00%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article89.text
Will force exclusive back-off from OOVs.
Perplexity = 182.19, Entropy = 7.51 bits
Computation based on 78 words.
Number of 5-grams hit = 14  (17.95%)
Number of 4-grams hit = 17  (21.79%)
Number of 3-grams hit = 21  (26.92%)
Number of 2-grams hit = 22  (28.21%)
Number of 1-grams hit = 4  (5.13%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article90.text
Will force exclusive back-off from OOVs.
Perplexity = 90.55, Entropy = 6.50 bits
Computation based on 70 words.
Number of 5-grams hit = 14  (20.00%)
Number of 4-grams hit = 20  (28.57%)
Number of 3-grams hit = 19  (27.14%)
Number of 2-grams hit = 12  (17.14%)
Number of 1-grams hit = 5  (7.14%)
2 OOVs (2.78%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article91.text
Will force exclusive back-off from OOVs.
Perplexity = 99.57, Entropy = 6.64 bits
Computation based on 45 words.
Number of 5-grams hit = 9  (20.00%)
Number of 4-grams hit = 10  (22.22%)
Number of 3-grams hit = 16  (35.56%)
Number of 2-grams hit = 9  (20.00%)
Number of 1-grams hit = 1  (2.22%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article92.text
Will force exclusive back-off from OOVs.
Perplexity = 128.74, Entropy = 7.01 bits
Computation based on 85 words.
Number of 5-grams hit = 16  (18.82%)
Number of 4-grams hit = 16  (18.82%)
Number of 3-grams hit = 28  (32.94%)
Number of 2-grams hit = 21  (24.71%)
Number of 1-grams hit = 4  (4.71%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article93.text
Will force exclusive back-off from OOVs.
Perplexity = 243.41, Entropy = 7.93 bits
Computation based on 138 words.
Number of 5-grams hit = 19  (13.77%)
Number of 4-grams hit = 32  (23.19%)
Number of 3-grams hit = 47  (34.06%)
Number of 2-grams hit = 31  (22.46%)
Number of 1-grams hit = 9  (6.52%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article94.text
Will force exclusive back-off from OOVs.
Perplexity = 6.07, Entropy = 2.60 bits
Computation based on 32 words.
Number of 5-grams hit = 24  (75.00%)
Number of 4-grams hit = 3  (9.38%)
Number of 3-grams hit = 2  (6.25%)
Number of 2-grams hit = 2  (6.25%)
Number of 1-grams hit = 1  (3.12%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article95.text
Will force exclusive back-off from OOVs.
Perplexity = 176.92, Entropy = 7.47 bits
Computation based on 154 words.
Number of 5-grams hit = 23  (14.94%)
Number of 4-grams hit = 37  (24.03%)
Number of 3-grams hit = 50  (32.47%)
Number of 2-grams hit = 30  (19.48%)
Number of 1-grams hit = 14  (9.09%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article96.text
Will force exclusive back-off from OOVs.
Perplexity = 270.83, Entropy = 8.08 bits
Computation based on 82 words.
Number of 5-grams hit = 13  (15.85%)
Number of 4-grams hit = 12  (14.63%)
Number of 3-grams hit = 18  (21.95%)
Number of 2-grams hit = 25  (30.49%)
Number of 1-grams hit = 14  (17.07%)
6 OOVs (6.82%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article97.text
Will force exclusive back-off from OOVs.
Perplexity = 43.91, Entropy = 5.46 bits
Computation based on 42 words.
Number of 5-grams hit = 16  (38.10%)
Number of 4-grams hit = 11  (26.19%)
Number of 3-grams hit = 8  (19.05%)
Number of 2-grams hit = 5  (11.90%)
Number of 1-grams hit = 2  (4.76%)
1 OOVs (2.33%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article98.text
Will force exclusive back-off from OOVs.
Perplexity = 227.81, Entropy = 7.83 bits
Computation based on 95 words.
Number of 5-grams hit = 12  (12.63%)
Number of 4-grams hit = 17  (17.89%)
Number of 3-grams hit = 25  (26.32%)
Number of 2-grams hit = 29  (30.53%)
Number of 1-grams hit = 12  (12.63%)
1 OOVs (1.04%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article99.text
Will force exclusive back-off from OOVs.
Perplexity = 177.37, Entropy = 7.47 bits
Computation based on 74 words.
Number of 5-grams hit = 15  (20.27%)
Number of 4-grams hit = 13  (17.57%)
Number of 3-grams hit = 24  (32.43%)
Number of 2-grams hit = 14  (18.92%)
Number of 1-grams hit = 8  (10.81%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article100.text
Will force exclusive back-off from OOVs.
Perplexity = 49.19, Entropy = 5.62 bits
Computation based on 97 words.
Number of 5-grams hit = 33  (34.02%)
Number of 4-grams hit = 23  (23.71%)
Number of 3-grams hit = 22  (22.68%)
Number of 2-grams hit = 15  (15.46%)
Number of 1-grams hit = 4  (4.12%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article101.text
Will force exclusive back-off from OOVs.
Perplexity = 108.82, Entropy = 6.77 bits
Computation based on 78 words.
Number of 5-grams hit = 12  (15.38%)
Number of 4-grams hit = 25  (32.05%)
Number of 3-grams hit = 24  (30.77%)
Number of 2-grams hit = 15  (19.23%)
Number of 1-grams hit = 2  (2.56%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article102.text
Will force exclusive back-off from OOVs.
Perplexity = 101.45, Entropy = 6.66 bits
Computation based on 87 words.
Number of 5-grams hit = 28  (32.18%)
Number of 4-grams hit = 15  (17.24%)
Number of 3-grams hit = 21  (24.14%)
Number of 2-grams hit = 14  (16.09%)
Number of 1-grams hit = 9  (10.34%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article103.text
Will force exclusive back-off from OOVs.
Perplexity = 111.14, Entropy = 6.80 bits
Computation based on 67 words.
Number of 5-grams hit = 18  (26.87%)
Number of 4-grams hit = 13  (19.40%)
Number of 3-grams hit = 17  (25.37%)
Number of 2-grams hit = 15  (22.39%)
Number of 1-grams hit = 4  (5.97%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article104.text
Will force exclusive back-off from OOVs.
Perplexity = 214.03, Entropy = 7.74 bits
Computation based on 68 words.
Number of 5-grams hit = 11  (16.18%)
Number of 4-grams hit = 13  (19.12%)
Number of 3-grams hit = 16  (23.53%)
Number of 2-grams hit = 21  (30.88%)
Number of 1-grams hit = 7  (10.29%)
1 OOVs (1.45%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article105.text
Will force exclusive back-off from OOVs.
Perplexity = 141.22, Entropy = 7.14 bits
Computation based on 90 words.
Number of 5-grams hit = 18  (20.00%)
Number of 4-grams hit = 19  (21.11%)
Number of 3-grams hit = 30  (33.33%)
Number of 2-grams hit = 16  (17.78%)
Number of 1-grams hit = 7  (7.78%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article106.text
Will force exclusive back-off from OOVs.
Perplexity = 43.72, Entropy = 5.45 bits
Computation based on 57 words.
Number of 5-grams hit = 20  (35.09%)
Number of 4-grams hit = 14  (24.56%)
Number of 3-grams hit = 15  (26.32%)
Number of 2-grams hit = 6  (10.53%)
Number of 1-grams hit = 2  (3.51%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article107.text
Will force exclusive back-off from OOVs.
Perplexity = 81.00, Entropy = 6.34 bits
Computation based on 40 words.
Number of 5-grams hit = 11  (27.50%)
Number of 4-grams hit = 10  (25.00%)
Number of 3-grams hit = 10  (25.00%)
Number of 2-grams hit = 6  (15.00%)
Number of 1-grams hit = 3  (7.50%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article108.text
Will force exclusive back-off from OOVs.
Perplexity = 21.51, Entropy = 4.43 bits
Computation based on 125 words.
Number of 5-grams hit = 71  (56.80%)
Number of 4-grams hit = 20  (16.00%)
Number of 3-grams hit = 23  (18.40%)
Number of 2-grams hit = 9  (7.20%)
Number of 1-grams hit = 2  (1.60%)
1 OOVs (0.79%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article109.text
Will force exclusive back-off from OOVs.
Perplexity = 201.15, Entropy = 7.65 bits
Computation based on 96 words.
Number of 5-grams hit = 16  (16.67%)
Number of 4-grams hit = 25  (26.04%)
Number of 3-grams hit = 26  (27.08%)
Number of 2-grams hit = 22  (22.92%)
Number of 1-grams hit = 7  (7.29%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article110.text
Will force exclusive back-off from OOVs.
Perplexity = 98.78, Entropy = 6.63 bits
Computation based on 120 words.
Number of 5-grams hit = 21  (17.50%)
Number of 4-grams hit = 31  (25.83%)
Number of 3-grams hit = 40  (33.33%)
Number of 2-grams hit = 24  (20.00%)
Number of 1-grams hit = 4  (3.33%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article111.text
Will force exclusive back-off from OOVs.
Perplexity = 108.93, Entropy = 6.77 bits
Computation based on 68 words.
Number of 5-grams hit = 11  (16.18%)
Number of 4-grams hit = 19  (27.94%)
Number of 3-grams hit = 26  (38.24%)
Number of 2-grams hit = 9  (13.24%)
Number of 1-grams hit = 3  (4.41%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article112.text
Will force exclusive back-off from OOVs.
Perplexity = 57.22, Entropy = 5.84 bits
Computation based on 89 words.
Number of 5-grams hit = 34  (38.20%)
Number of 4-grams hit = 20  (22.47%)
Number of 3-grams hit = 20  (22.47%)
Number of 2-grams hit = 11  (12.36%)
Number of 1-grams hit = 4  (4.49%)
1 OOVs (1.11%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article113.text
Will force exclusive back-off from OOVs.
Perplexity = 164.67, Entropy = 7.36 bits
Computation based on 94 words.
Number of 5-grams hit = 20  (21.28%)
Number of 4-grams hit = 18  (19.15%)
Number of 3-grams hit = 28  (29.79%)
Number of 2-grams hit = 23  (24.47%)
Number of 1-grams hit = 5  (5.32%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article114.text
Will force exclusive back-off from OOVs.
Perplexity = 133.62, Entropy = 7.06 bits
Computation based on 143 words.
Number of 5-grams hit = 37  (25.87%)
Number of 4-grams hit = 22  (15.38%)
Number of 3-grams hit = 32  (22.38%)
Number of 2-grams hit = 38  (26.57%)
Number of 1-grams hit = 14  (9.79%)
1 OOVs (0.69%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article115.text
Will force exclusive back-off from OOVs.
Perplexity = 72.76, Entropy = 6.18 bits
Computation based on 71 words.
Number of 5-grams hit = 18  (25.35%)
Number of 4-grams hit = 19  (26.76%)
Number of 3-grams hit = 24  (33.80%)
Number of 2-grams hit = 8  (11.27%)
Number of 1-grams hit = 2  (2.82%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article116.text
Will force exclusive back-off from OOVs.
Perplexity = 177.81, Entropy = 7.47 bits
Computation based on 112 words.
Number of 5-grams hit = 10  (8.93%)
Number of 4-grams hit = 28  (25.00%)
Number of 3-grams hit = 38  (33.93%)
Number of 2-grams hit = 30  (26.79%)
Number of 1-grams hit = 6  (5.36%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article117.text
Will force exclusive back-off from OOVs.
Perplexity = 75.90, Entropy = 6.25 bits
Computation based on 82 words.
Number of 5-grams hit = 10  (12.20%)
Number of 4-grams hit = 30  (36.59%)
Number of 3-grams hit = 27  (32.93%)
Number of 2-grams hit = 13  (15.85%)
Number of 1-grams hit = 2  (2.44%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article118.text
Will force exclusive back-off from OOVs.
Perplexity = 80.23, Entropy = 6.33 bits
Computation based on 91 words.
Number of 5-grams hit = 18  (19.78%)
Number of 4-grams hit = 27  (29.67%)
Number of 3-grams hit = 21  (23.08%)
Number of 2-grams hit = 19  (20.88%)
Number of 1-grams hit = 6  (6.59%)
2 OOVs (2.15%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article119.text
Will force exclusive back-off from OOVs.
Perplexity = 112.19, Entropy = 6.81 bits
Computation based on 48 words.
Number of 5-grams hit = 10  (20.83%)
Number of 4-grams hit = 13  (27.08%)
Number of 3-grams hit = 12  (25.00%)
Number of 2-grams hit = 10  (20.83%)
Number of 1-grams hit = 3  (6.25%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article120.text
Will force exclusive back-off from OOVs.
Perplexity = 69.83, Entropy = 6.13 bits
Computation based on 125 words.
Number of 5-grams hit = 41  (32.80%)
Number of 4-grams hit = 28  (22.40%)
Number of 3-grams hit = 29  (23.20%)
Number of 2-grams hit = 21  (16.80%)
Number of 1-grams hit = 6  (4.80%)
2 OOVs (1.57%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article121.text
Will force exclusive back-off from OOVs.
Perplexity = 299.56, Entropy = 8.23 bits
Computation based on 156 words.
Number of 5-grams hit = 18  (11.54%)
Number of 4-grams hit = 36  (23.08%)
Number of 3-grams hit = 44  (28.21%)
Number of 2-grams hit = 42  (26.92%)
Number of 1-grams hit = 16  (10.26%)
2 OOVs (1.27%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article122.text
Will force exclusive back-off from OOVs.
Perplexity = 44.78, Entropy = 5.48 bits
Computation based on 97 words.
Number of 5-grams hit = 45  (46.39%)
Number of 4-grams hit = 18  (18.56%)
Number of 3-grams hit = 15  (15.46%)
Number of 2-grams hit = 15  (15.46%)
Number of 1-grams hit = 4  (4.12%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article123.text
Will force exclusive back-off from OOVs.
Perplexity = 45.12, Entropy = 5.50 bits
Computation based on 56 words.
Number of 5-grams hit = 21  (37.50%)
Number of 4-grams hit = 17  (30.36%)
Number of 3-grams hit = 12  (21.43%)
Number of 2-grams hit = 5  (8.93%)
Number of 1-grams hit = 1  (1.79%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article124.text
Will force exclusive back-off from OOVs.
Perplexity = 72.04, Entropy = 6.17 bits
Computation based on 143 words.
Number of 5-grams hit = 40  (27.97%)
Number of 4-grams hit = 31  (21.68%)
Number of 3-grams hit = 43  (30.07%)
Number of 2-grams hit = 24  (16.78%)
Number of 1-grams hit = 5  (3.50%)
2 OOVs (1.38%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article125.text
Will force exclusive back-off from OOVs.
Perplexity = 85.05, Entropy = 6.41 bits
Computation based on 95 words.
Number of 5-grams hit = 35  (36.84%)
Number of 4-grams hit = 19  (20.00%)
Number of 3-grams hit = 20  (21.05%)
Number of 2-grams hit = 17  (17.89%)
Number of 1-grams hit = 4  (4.21%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article126.text
Will force exclusive back-off from OOVs.
Perplexity = 166.04, Entropy = 7.38 bits
Computation based on 135 words.
Number of 5-grams hit = 21  (15.56%)
Number of 4-grams hit = 23  (17.04%)
Number of 3-grams hit = 47  (34.81%)
Number of 2-grams hit = 25  (18.52%)
Number of 1-grams hit = 19  (14.07%)
11 OOVs (7.53%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article127.text
Will force exclusive back-off from OOVs.
Perplexity = 149.56, Entropy = 7.22 bits
Computation based on 155 words.
Number of 5-grams hit = 31  (20.00%)
Number of 4-grams hit = 38  (24.52%)
Number of 3-grams hit = 45  (29.03%)
Number of 2-grams hit = 29  (18.71%)
Number of 1-grams hit = 12  (7.74%)
5 OOVs (3.12%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article128.text
Will force exclusive back-off from OOVs.
Perplexity = 62.89, Entropy = 5.97 bits
Computation based on 82 words.
Number of 5-grams hit = 25  (30.49%)
Number of 4-grams hit = 19  (23.17%)
Number of 3-grams hit = 20  (24.39%)
Number of 2-grams hit = 14  (17.07%)
Number of 1-grams hit = 4  (4.88%)
1 OOVs (1.20%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article129.text
Will force exclusive back-off from OOVs.
Perplexity = 93.73, Entropy = 6.55 bits
Computation based on 116 words.
Number of 5-grams hit = 23  (19.83%)
Number of 4-grams hit = 30  (25.86%)
Number of 3-grams hit = 37  (31.90%)
Number of 2-grams hit = 20  (17.24%)
Number of 1-grams hit = 6  (5.17%)
1 OOVs (0.85%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article130.text
Will force exclusive back-off from OOVs.
Perplexity = 41.59, Entropy = 5.38 bits
Computation based on 135 words.
Number of 5-grams hit = 58  (42.96%)
Number of 4-grams hit = 23  (17.04%)
Number of 3-grams hit = 33  (24.44%)
Number of 2-grams hit = 16  (11.85%)
Number of 1-grams hit = 5  (3.70%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article131.text
Will force exclusive back-off from OOVs.
Perplexity = 80.78, Entropy = 6.34 bits
Computation based on 66 words.
Number of 5-grams hit = 14  (21.21%)
Number of 4-grams hit = 22  (33.33%)
Number of 3-grams hit = 19  (28.79%)
Number of 2-grams hit = 10  (15.15%)
Number of 1-grams hit = 1  (1.52%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article132.text
Will force exclusive back-off from OOVs.
Perplexity = 74.28, Entropy = 6.21 bits
Computation based on 128 words.
Number of 5-grams hit = 38  (29.69%)
Number of 4-grams hit = 30  (23.44%)
Number of 3-grams hit = 35  (27.34%)
Number of 2-grams hit = 23  (17.97%)
Number of 1-grams hit = 2  (1.56%)
1 OOVs (0.78%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article133.text
Will force exclusive back-off from OOVs.
Perplexity = 119.26, Entropy = 6.90 bits
Computation based on 99 words.
Number of 5-grams hit = 17  (17.17%)
Number of 4-grams hit = 19  (19.19%)
Number of 3-grams hit = 33  (33.33%)
Number of 2-grams hit = 27  (27.27%)
Number of 1-grams hit = 3  (3.03%)
1 OOVs (1.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article134.text
Will force exclusive back-off from OOVs.
Perplexity = 27.40, Entropy = 4.78 bits
Computation based on 79 words.
Number of 5-grams hit = 45  (56.96%)
Number of 4-grams hit = 10  (12.66%)
Number of 3-grams hit = 11  (13.92%)
Number of 2-grams hit = 11  (13.92%)
Number of 1-grams hit = 2  (2.53%)
1 OOVs (1.25%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article135.text
Will force exclusive back-off from OOVs.
Perplexity = 127.19, Entropy = 6.99 bits
Computation based on 74 words.
Number of 5-grams hit = 15  (20.27%)
Number of 4-grams hit = 17  (22.97%)
Number of 3-grams hit = 21  (28.38%)
Number of 2-grams hit = 16  (21.62%)
Number of 1-grams hit = 5  (6.76%)
1 OOVs (1.33%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article136.text
Will force exclusive back-off from OOVs.
Perplexity = 179.06, Entropy = 7.48 bits
Computation based on 121 words.
Number of 5-grams hit = 22  (18.18%)
Number of 4-grams hit = 16  (13.22%)
Number of 3-grams hit = 33  (27.27%)
Number of 2-grams hit = 31  (25.62%)
Number of 1-grams hit = 19  (15.70%)
8 OOVs (6.20%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article137.text
Will force exclusive back-off from OOVs.
Perplexity = 132.86, Entropy = 7.05 bits
Computation based on 141 words.
Number of 5-grams hit = 26  (18.44%)
Number of 4-grams hit = 41  (29.08%)
Number of 3-grams hit = 47  (33.33%)
Number of 2-grams hit = 21  (14.89%)
Number of 1-grams hit = 6  (4.26%)
1 OOVs (0.70%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article138.text
Will force exclusive back-off from OOVs.
Perplexity = 65.92, Entropy = 6.04 bits
Computation based on 94 words.
Number of 5-grams hit = 36  (38.30%)
Number of 4-grams hit = 16  (17.02%)
Number of 3-grams hit = 22  (23.40%)
Number of 2-grams hit = 16  (17.02%)
Number of 1-grams hit = 4  (4.26%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article139.text
Will force exclusive back-off from OOVs.
Perplexity = 175.23, Entropy = 7.45 bits
Computation based on 111 words.
Number of 5-grams hit = 19  (17.12%)
Number of 4-grams hit = 24  (21.62%)
Number of 3-grams hit = 34  (30.63%)
Number of 2-grams hit = 26  (23.42%)
Number of 1-grams hit = 8  (7.21%)
2 OOVs (1.77%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article140.text
Will force exclusive back-off from OOVs.
Perplexity = 215.06, Entropy = 7.75 bits
Computation based on 200 words.
Number of 5-grams hit = 29  (14.50%)
Number of 4-grams hit = 38  (19.00%)
Number of 3-grams hit = 64  (32.00%)
Number of 2-grams hit = 55  (27.50%)
Number of 1-grams hit = 14  (7.00%)
1 OOVs (0.50%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article141.text
Will force exclusive back-off from OOVs.
Perplexity = 140.20, Entropy = 7.13 bits
Computation based on 132 words.
Number of 5-grams hit = 27  (20.45%)
Number of 4-grams hit = 31  (23.48%)
Number of 3-grams hit = 40  (30.30%)
Number of 2-grams hit = 27  (20.45%)
Number of 1-grams hit = 7  (5.30%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article142.text
Will force exclusive back-off from OOVs.
Perplexity = 90.78, Entropy = 6.50 bits
Computation based on 100 words.
Number of 5-grams hit = 35  (35.00%)
Number of 4-grams hit = 19  (19.00%)
Number of 3-grams hit = 23  (23.00%)
Number of 2-grams hit = 18  (18.00%)
Number of 1-grams hit = 5  (5.00%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article143.text
Will force exclusive back-off from OOVs.
Perplexity = 118.75, Entropy = 6.89 bits
Computation based on 185 words.
Number of 5-grams hit = 36  (19.46%)
Number of 4-grams hit = 53  (28.65%)
Number of 3-grams hit = 58  (31.35%)
Number of 2-grams hit = 31  (16.76%)
Number of 1-grams hit = 7  (3.78%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article144.text
Will force exclusive back-off from OOVs.
Perplexity = 71.33, Entropy = 6.16 bits
Computation based on 103 words.
Number of 5-grams hit = 44  (42.72%)
Number of 4-grams hit = 12  (11.65%)
Number of 3-grams hit = 20  (19.42%)
Number of 2-grams hit = 18  (17.48%)
Number of 1-grams hit = 9  (8.74%)
1 OOVs (0.96%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article145.text
Will force exclusive back-off from OOVs.
Perplexity = 176.51, Entropy = 7.46 bits
Computation based on 278 words.
Number of 5-grams hit = 46  (16.55%)
Number of 4-grams hit = 74  (26.62%)
Number of 3-grams hit = 93  (33.45%)
Number of 2-grams hit = 49  (17.63%)
Number of 1-grams hit = 16  (5.76%)
1 OOVs (0.36%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article146.text
Will force exclusive back-off from OOVs.
Perplexity = 62.78, Entropy = 5.97 bits
Computation based on 187 words.
Number of 5-grams hit = 58  (31.02%)
Number of 4-grams hit = 49  (26.20%)
Number of 3-grams hit = 52  (27.81%)
Number of 2-grams hit = 26  (13.90%)
Number of 1-grams hit = 2  (1.07%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article147.text
Will force exclusive back-off from OOVs.
Perplexity = 171.22, Entropy = 7.42 bits
Computation based on 178 words.
Number of 5-grams hit = 28  (15.73%)
Number of 4-grams hit = 42  (23.60%)
Number of 3-grams hit = 63  (35.39%)
Number of 2-grams hit = 36  (20.22%)
Number of 1-grams hit = 9  (5.06%)
1 OOVs (0.56%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article148.text
Will force exclusive back-off from OOVs.
Perplexity = 5.35, Entropy = 2.42 bits
Computation based on 114 words.
Number of 5-grams hit = 108  (94.74%)
Number of 4-grams hit = 2  (1.75%)
Number of 3-grams hit = 1  (0.88%)
Number of 2-grams hit = 1  (0.88%)
Number of 1-grams hit = 2  (1.75%)
1 OOVs (0.87%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article149.text
Will force exclusive back-off from OOVs.
Perplexity = 93.50, Entropy = 6.55 bits
Computation based on 134 words.
Number of 5-grams hit = 30  (22.39%)
Number of 4-grams hit = 34  (25.37%)
Number of 3-grams hit = 47  (35.07%)
Number of 2-grams hit = 19  (14.18%)
Number of 1-grams hit = 4  (2.99%)
2 OOVs (1.47%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article150.text
Will force exclusive back-off from OOVs.
Perplexity = 59.42, Entropy = 5.89 bits
Computation based on 219 words.
Number of 5-grams hit = 72  (32.88%)
Number of 4-grams hit = 57  (26.03%)
Number of 3-grams hit = 50  (22.83%)
Number of 2-grams hit = 34  (15.53%)
Number of 1-grams hit = 6  (2.74%)
1 OOVs (0.45%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article151.text
Will force exclusive back-off from OOVs.
Perplexity = 127.11, Entropy = 6.99 bits
Computation based on 151 words.
Number of 5-grams hit = 33  (21.85%)
Number of 4-grams hit = 41  (27.15%)
Number of 3-grams hit = 43  (28.48%)
Number of 2-grams hit = 26  (17.22%)
Number of 1-grams hit = 8  (5.30%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article152.text
Will force exclusive back-off from OOVs.
Perplexity = 62.94, Entropy = 5.98 bits
Computation based on 123 words.
Number of 5-grams hit = 34  (27.64%)
Number of 4-grams hit = 36  (29.27%)
Number of 3-grams hit = 33  (26.83%)
Number of 2-grams hit = 18  (14.63%)
Number of 1-grams hit = 2  (1.63%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article153.text
Will force exclusive back-off from OOVs.
Perplexity = 291.86, Entropy = 8.19 bits
Computation based on 250 words.
Number of 5-grams hit = 40  (16.00%)
Number of 4-grams hit = 45  (18.00%)
Number of 3-grams hit = 76  (30.40%)
Number of 2-grams hit = 62  (24.80%)
Number of 1-grams hit = 27  (10.80%)
2 OOVs (0.79%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article154.text
Will force exclusive back-off from OOVs.
Perplexity = 125.25, Entropy = 6.97 bits
Computation based on 183 words.
Number of 5-grams hit = 40  (21.86%)
Number of 4-grams hit = 41  (22.40%)
Number of 3-grams hit = 42  (22.95%)
Number of 2-grams hit = 45  (24.59%)
Number of 1-grams hit = 15  (8.20%)
7 OOVs (3.68%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article155.text
Will force exclusive back-off from OOVs.
Perplexity = 149.22, Entropy = 7.22 bits
Computation based on 156 words.
Number of 5-grams hit = 29  (18.59%)
Number of 4-grams hit = 36  (23.08%)
Number of 3-grams hit = 53  (33.97%)
Number of 2-grams hit = 31  (19.87%)
Number of 1-grams hit = 7  (4.49%)
1 OOVs (0.64%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article156.text
Will force exclusive back-off from OOVs.
Perplexity = 28.74, Entropy = 4.84 bits
Computation based on 171 words.
Number of 5-grams hit = 78  (45.61%)
Number of 4-grams hit = 37  (21.64%)
Number of 3-grams hit = 28  (16.37%)
Number of 2-grams hit = 20  (11.70%)
Number of 1-grams hit = 8  (4.68%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article157.text
Will force exclusive back-off from OOVs.
Perplexity = 99.80, Entropy = 6.64 bits
Computation based on 137 words.
Number of 5-grams hit = 35  (25.55%)
Number of 4-grams hit = 33  (24.09%)
Number of 3-grams hit = 41  (29.93%)
Number of 2-grams hit = 24  (17.52%)
Number of 1-grams hit = 4  (2.92%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article158.text
Will force exclusive back-off from OOVs.
Perplexity = 103.34, Entropy = 6.69 bits
Computation based on 174 words.
Number of 5-grams hit = 49  (28.16%)
Number of 4-grams hit = 36  (20.69%)
Number of 3-grams hit = 46  (26.44%)
Number of 2-grams hit = 37  (21.26%)
Number of 1-grams hit = 6  (3.45%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article159.text
Will force exclusive back-off from OOVs.
Perplexity = 169.53, Entropy = 7.41 bits
Computation based on 173 words.
Number of 5-grams hit = 26  (15.03%)
Number of 4-grams hit = 37  (21.39%)
Number of 3-grams hit = 62  (35.84%)
Number of 2-grams hit = 37  (21.39%)
Number of 1-grams hit = 11  (6.36%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article160.text
Will force exclusive back-off from OOVs.
Perplexity = 68.81, Entropy = 6.10 bits
Computation based on 249 words.
Number of 5-grams hit = 79  (31.73%)
Number of 4-grams hit = 46  (18.47%)
Number of 3-grams hit = 72  (28.92%)
Number of 2-grams hit = 37  (14.86%)
Number of 1-grams hit = 15  (6.02%)
4 OOVs (1.58%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article161.text
Will force exclusive back-off from OOVs.
Perplexity = 154.36, Entropy = 7.27 bits
Computation based on 276 words.
Number of 5-grams hit = 42  (15.22%)
Number of 4-grams hit = 66  (23.91%)
Number of 3-grams hit = 107  (38.77%)
Number of 2-grams hit = 49  (17.75%)
Number of 1-grams hit = 12  (4.35%)
1 OOVs (0.36%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article162.text
Will force exclusive back-off from OOVs.
Perplexity = 87.36, Entropy = 6.45 bits
Computation based on 208 words.
Number of 5-grams hit = 51  (24.52%)
Number of 4-grams hit = 49  (23.56%)
Number of 3-grams hit = 51  (24.52%)
Number of 2-grams hit = 42  (20.19%)
Number of 1-grams hit = 15  (7.21%)
7 OOVs (3.26%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article163.text
Will force exclusive back-off from OOVs.
Perplexity = 124.20, Entropy = 6.96 bits
Computation based on 275 words.
Number of 5-grams hit = 61  (22.18%)
Number of 4-grams hit = 67  (24.36%)
Number of 3-grams hit = 83  (30.18%)
Number of 2-grams hit = 51  (18.55%)
Number of 1-grams hit = 13  (4.73%)
2 OOVs (0.72%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article164.text
Will force exclusive back-off from OOVs.
Perplexity = 54.47, Entropy = 5.77 bits
Computation based on 236 words.
Number of 5-grams hit = 84  (35.59%)
Number of 4-grams hit = 51  (21.61%)
Number of 3-grams hit = 63  (26.69%)
Number of 2-grams hit = 34  (14.41%)
Number of 1-grams hit = 4  (1.69%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article165.text
Will force exclusive back-off from OOVs.
Perplexity = 175.96, Entropy = 7.46 bits
Computation based on 280 words.
Number of 5-grams hit = 59  (21.07%)
Number of 4-grams hit = 59  (21.07%)
Number of 3-grams hit = 80  (28.57%)
Number of 2-grams hit = 66  (23.57%)
Number of 1-grams hit = 16  (5.71%)
1 OOVs (0.36%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article166.text
Will force exclusive back-off from OOVs.
Perplexity = 197.79, Entropy = 7.63 bits
Computation based on 289 words.
Number of 5-grams hit = 46  (15.92%)
Number of 4-grams hit = 49  (16.96%)
Number of 3-grams hit = 77  (26.64%)
Number of 2-grams hit = 83  (28.72%)
Number of 1-grams hit = 34  (11.76%)
10 OOVs (3.34%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article167.text
Will force exclusive back-off from OOVs.
Perplexity = 105.75, Entropy = 6.72 bits
Computation based on 231 words.
Number of 5-grams hit = 65  (28.14%)
Number of 4-grams hit = 60  (25.97%)
Number of 3-grams hit = 62  (26.84%)
Number of 2-grams hit = 28  (12.12%)
Number of 1-grams hit = 16  (6.93%)
1 OOVs (0.43%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article168.text
Will force exclusive back-off from OOVs.
Perplexity = 41.15, Entropy = 5.36 bits
Computation based on 118 words.
Number of 5-grams hit = 49  (41.53%)
Number of 4-grams hit = 25  (21.19%)
Number of 3-grams hit = 26  (22.03%)
Number of 2-grams hit = 15  (12.71%)
Number of 1-grams hit = 3  (2.54%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article169.text
Will force exclusive back-off from OOVs.
Perplexity = 165.94, Entropy = 7.37 bits
Computation based on 339 words.
Number of 5-grams hit = 47  (13.86%)
Number of 4-grams hit = 84  (24.78%)
Number of 3-grams hit = 118  (34.81%)
Number of 2-grams hit = 70  (20.65%)
Number of 1-grams hit = 20  (5.90%)
6 OOVs (1.74%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article170.text
Will force exclusive back-off from OOVs.
Perplexity = 72.18, Entropy = 6.17 bits
Computation based on 263 words.
Number of 5-grams hit = 91  (34.60%)
Number of 4-grams hit = 66  (25.10%)
Number of 3-grams hit = 60  (22.81%)
Number of 2-grams hit = 35  (13.31%)
Number of 1-grams hit = 11  (4.18%)
2 OOVs (0.75%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article171.text
Will force exclusive back-off from OOVs.
Perplexity = 106.18, Entropy = 6.73 bits
Computation based on 288 words.
Number of 5-grams hit = 77  (26.74%)
Number of 4-grams hit = 58  (20.14%)
Number of 3-grams hit = 82  (28.47%)
Number of 2-grams hit = 59  (20.49%)
Number of 1-grams hit = 12  (4.17%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article172.text
Will force exclusive back-off from OOVs.
Perplexity = 74.78, Entropy = 6.22 bits
Computation based on 195 words.
Number of 5-grams hit = 71  (36.41%)
Number of 4-grams hit = 33  (16.92%)
Number of 3-grams hit = 45  (23.08%)
Number of 2-grams hit = 33  (16.92%)
Number of 1-grams hit = 13  (6.67%)
2 OOVs (1.02%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article173.text
Will force exclusive back-off from OOVs.
Perplexity = 138.90, Entropy = 7.12 bits
Computation based on 243 words.
Number of 5-grams hit = 45  (18.52%)
Number of 4-grams hit = 69  (28.40%)
Number of 3-grams hit = 75  (30.86%)
Number of 2-grams hit = 38  (15.64%)
Number of 1-grams hit = 16  (6.58%)
1 OOVs (0.41%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article174.text
Will force exclusive back-off from OOVs.
Perplexity = 29.13, Entropy = 4.86 bits
Computation based on 203 words.
Number of 5-grams hit = 85  (41.87%)
Number of 4-grams hit = 42  (20.69%)
Number of 3-grams hit = 48  (23.65%)
Number of 2-grams hit = 23  (11.33%)
Number of 1-grams hit = 5  (2.46%)
1 OOVs (0.49%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article175.text
Will force exclusive back-off from OOVs.
Perplexity = 153.02, Entropy = 7.26 bits
Computation based on 428 words.
Number of 5-grams hit = 83  (19.39%)
Number of 4-grams hit = 106  (24.77%)
Number of 3-grams hit = 140  (32.71%)
Number of 2-grams hit = 76  (17.76%)
Number of 1-grams hit = 23  (5.37%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article176.text
Will force exclusive back-off from OOVs.
Perplexity = 63.60, Entropy = 5.99 bits
Computation based on 256 words.
Number of 5-grams hit = 85  (33.20%)
Number of 4-grams hit = 49  (19.14%)
Number of 3-grams hit = 71  (27.73%)
Number of 2-grams hit = 43  (16.80%)
Number of 1-grams hit = 8  (3.12%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article177.text
Will force exclusive back-off from OOVs.
Perplexity = 170.67, Entropy = 7.42 bits
Computation based on 293 words.
Number of 5-grams hit = 62  (21.16%)
Number of 4-grams hit = 66  (22.53%)
Number of 3-grams hit = 81  (27.65%)
Number of 2-grams hit = 68  (23.21%)
Number of 1-grams hit = 16  (5.46%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article178.text
Will force exclusive back-off from OOVs.
Perplexity = 107.06, Entropy = 6.74 bits
Computation based on 165 words.
Number of 5-grams hit = 49  (29.70%)
Number of 4-grams hit = 32  (19.39%)
Number of 3-grams hit = 40  (24.24%)
Number of 2-grams hit = 36  (21.82%)
Number of 1-grams hit = 8  (4.85%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article179.text
Will force exclusive back-off from OOVs.
Perplexity = 124.62, Entropy = 6.96 bits
Computation based on 243 words.
Number of 5-grams hit = 69  (28.40%)
Number of 4-grams hit = 56  (23.05%)
Number of 3-grams hit = 59  (24.28%)
Number of 2-grams hit = 44  (18.11%)
Number of 1-grams hit = 15  (6.17%)
1 OOVs (0.41%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article180.text
Will force exclusive back-off from OOVs.
Perplexity = 60.88, Entropy = 5.93 bits
Computation based on 192 words.
Number of 5-grams hit = 67  (34.90%)
Number of 4-grams hit = 37  (19.27%)
Number of 3-grams hit = 56  (29.17%)
Number of 2-grams hit = 30  (15.62%)
Number of 1-grams hit = 2  (1.04%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article181.text
Will force exclusive back-off from OOVs.
Perplexity = 133.38, Entropy = 7.06 bits
Computation based on 298 words.
Number of 5-grams hit = 64  (21.48%)
Number of 4-grams hit = 74  (24.83%)
Number of 3-grams hit = 93  (31.21%)
Number of 2-grams hit = 53  (17.79%)
Number of 1-grams hit = 14  (4.70%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article182.text
Will force exclusive back-off from OOVs.
Perplexity = 34.24, Entropy = 5.10 bits
Computation based on 254 words.
Number of 5-grams hit = 102  (40.16%)
Number of 4-grams hit = 54  (21.26%)
Number of 3-grams hit = 57  (22.44%)
Number of 2-grams hit = 35  (13.78%)
Number of 1-grams hit = 6  (2.36%)
5 OOVs (1.93%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article183.text
Will force exclusive back-off from OOVs.
Perplexity = 112.73, Entropy = 6.82 bits
Computation based on 291 words.
Number of 5-grams hit = 68  (23.37%)
Number of 4-grams hit = 94  (32.30%)
Number of 3-grams hit = 75  (25.77%)
Number of 2-grams hit = 45  (15.46%)
Number of 1-grams hit = 9  (3.09%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article184.text
Will force exclusive back-off from OOVs.
Perplexity = 80.49, Entropy = 6.33 bits
Computation based on 315 words.
Number of 5-grams hit = 99  (31.43%)
Number of 4-grams hit = 71  (22.54%)
Number of 3-grams hit = 86  (27.30%)
Number of 2-grams hit = 50  (15.87%)
Number of 1-grams hit = 9  (2.86%)
4 OOVs (1.25%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article185.text
Will force exclusive back-off from OOVs.
Perplexity = 147.35, Entropy = 7.20 bits
Computation based on 443 words.
Number of 5-grams hit = 89  (20.09%)
Number of 4-grams hit = 113  (25.51%)
Number of 3-grams hit = 127  (28.67%)
Number of 2-grams hit = 83  (18.74%)
Number of 1-grams hit = 31  (7.00%)
1 OOVs (0.23%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article186.text
Will force exclusive back-off from OOVs.
Perplexity = 44.05, Entropy = 5.46 bits
Computation based on 230 words.
Number of 5-grams hit = 104  (45.22%)
Number of 4-grams hit = 49  (21.30%)
Number of 3-grams hit = 51  (22.17%)
Number of 2-grams hit = 20  (8.70%)
Number of 1-grams hit = 6  (2.61%)
2 OOVs (0.86%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article187.text
Will force exclusive back-off from OOVs.
Perplexity = 158.29, Entropy = 7.31 bits
Computation based on 327 words.
Number of 5-grams hit = 68  (20.80%)
Number of 4-grams hit = 84  (25.69%)
Number of 3-grams hit = 96  (29.36%)
Number of 2-grams hit = 57  (17.43%)
Number of 1-grams hit = 22  (6.73%)
1 OOVs (0.30%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article188.text
Will force exclusive back-off from OOVs.
Perplexity = 77.34, Entropy = 6.27 bits
Computation based on 302 words.
Number of 5-grams hit = 110  (36.42%)
Number of 4-grams hit = 58  (19.21%)
Number of 3-grams hit = 68  (22.52%)
Number of 2-grams hit = 48  (15.89%)
Number of 1-grams hit = 18  (5.96%)
2 OOVs (0.66%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article189.text
Will force exclusive back-off from OOVs.
Perplexity = 193.34, Entropy = 7.60 bits
Computation based on 377 words.
Number of 5-grams hit = 64  (16.98%)
Number of 4-grams hit = 77  (20.42%)
Number of 3-grams hit = 129  (34.22%)
Number of 2-grams hit = 80  (21.22%)
Number of 1-grams hit = 27  (7.16%)
3 OOVs (0.79%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article190.text
Will force exclusive back-off from OOVs.
Perplexity = 35.60, Entropy = 5.15 bits
Computation based on 206 words.
Number of 5-grams hit = 101  (49.03%)
Number of 4-grams hit = 40  (19.42%)
Number of 3-grams hit = 46  (22.33%)
Number of 2-grams hit = 18  (8.74%)
Number of 1-grams hit = 1  (0.49%)
0 OOVs (0.00%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article191.text
Will force exclusive back-off from OOVs.
Perplexity = 138.90, Entropy = 7.12 bits
Computation based on 341 words.
Number of 5-grams hit = 62  (18.18%)
Number of 4-grams hit = 89  (26.10%)
Number of 3-grams hit = 114  (33.43%)
Number of 2-grams hit = 60  (17.60%)
Number of 1-grams hit = 16  (4.69%)
1 OOVs (0.29%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article192.text
Will force exclusive back-off from OOVs.
Perplexity = 40.11, Entropy = 5.33 bits
Computation based on 276 words.
Number of 5-grams hit = 119  (43.12%)
Number of 4-grams hit = 61  (22.10%)
Number of 3-grams hit = 68  (24.64%)
Number of 2-grams hit = 22  (7.97%)
Number of 1-grams hit = 6  (2.17%)
3 OOVs (1.08%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article193.text
Will force exclusive back-off from OOVs.
Perplexity = 123.72, Entropy = 6.95 bits
Computation based on 272 words.
Number of 5-grams hit = 64  (23.53%)
Number of 4-grams hit = 65  (23.90%)
Number of 3-grams hit = 82  (30.15%)
Number of 2-grams hit = 49  (18.01%)
Number of 1-grams hit = 12  (4.41%)
1 OOVs (0.37%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article194.text
Will force exclusive back-off from OOVs.
Perplexity = 129.99, Entropy = 7.02 bits
Computation based on 237 words.
Number of 5-grams hit = 51  (21.52%)
Number of 4-grams hit = 51  (21.52%)
Number of 3-grams hit = 62  (26.16%)
Number of 2-grams hit = 54  (22.78%)
Number of 1-grams hit = 19  (8.02%)
8 OOVs (3.27%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article195.text
Will force exclusive back-off from OOVs.
Perplexity = 161.96, Entropy = 7.34 bits
Computation based on 391 words.
Number of 5-grams hit = 77  (19.69%)
Number of 4-grams hit = 93  (23.79%)
Number of 3-grams hit = 115  (29.41%)
Number of 2-grams hit = 85  (21.74%)
Number of 1-grams hit = 21  (5.37%)
2 OOVs (0.51%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article196.text
Will force exclusive back-off from OOVs.
Perplexity = 176.59, Entropy = 7.46 bits
Computation based on 499 words.
Number of 5-grams hit = 101  (20.24%)
Number of 4-grams hit = 96  (19.24%)
Number of 3-grams hit = 152  (30.46%)
Number of 2-grams hit = 117  (23.45%)
Number of 1-grams hit = 33  (6.61%)
5 OOVs (0.99%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article197.text
Will force exclusive back-off from OOVs.
Perplexity = 146.35, Entropy = 7.19 bits
Computation based on 363 words.
Number of 5-grams hit = 74  (20.39%)
Number of 4-grams hit = 98  (27.00%)
Number of 3-grams hit = 108  (29.75%)
Number of 2-grams hit = 61  (16.80%)
Number of 1-grams hit = 22  (6.06%)
3 OOVs (0.82%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article198.text
Will force exclusive back-off from OOVs.
Perplexity = 47.32, Entropy = 5.56 bits
Computation based on 309 words.
Number of 5-grams hit = 137  (44.34%)
Number of 4-grams hit = 58  (18.77%)
Number of 3-grams hit = 63  (20.39%)
Number of 2-grams hit = 44  (14.24%)
Number of 1-grams hit = 7  (2.27%)
1 OOVs (0.32%) and 0 context cues were removed from the calculation.
evallm : Computing perplexity of the language model with respect
   to the text ../../data/devArticles/article199.text
Will force exclusive back-off from OOVs.
Perplexity = 122.26, Entropy = 6.93 bits
Computation based on 353 words.
Number of 5-grams hit = 78  (22.10%)
Number of 4-grams hit = 89  (25.21%)
Number of 3-grams hit = 104  (29.46%)
Number of 2-grams hit = 58  (16.43%)
Number of 1-grams hit = 24  (6.80%)
4 OOVs (1.12%) and 0 context cues were removed from the calculation.
evallm : 